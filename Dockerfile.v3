# AHGD V3: Modern Analytics Engineering Platform - Airflow Service
# Optimized for high-performance data processing with Polars + DuckDB

FROM apache/airflow:2.8.1-python3.11

USER root

# Install system dependencies for geospatial and performance libraries
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    libgdal-dev \
    libproj-dev \
    libgeos-dev \
    libspatialindex-dev \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

USER airflow

# Install modern data stack dependencies with pinned versions for stability
RUN pip install --no-cache-dir --upgrade pip

# Core data processing stack (high priority)
RUN pip install --no-cache-dir \
    'polars[all]>=0.20.0' \
    'duckdb>=0.9.0' \
    'dbt-core>=1.7.0' \
    'dbt-duckdb>=1.7.0' \
    'pyarrow>=15.0.0' \
    'fastparquet>=2024.2.0'

# Data validation and schema management
RUN pip install --no-cache-dir \
    'pydantic>=2.5.0' \
    'pydantic-settings>=2.1.0' \
    'jsonschema>=4.20.0' \
    'cerberus>=1.3.4'

# Geospatial processing libraries
RUN pip install --no-cache-dir \
    'geopandas>=0.14.0' \
    'shapely>=2.0.0' \
    'fiona>=1.9.0' \
    'pyproj>=3.6.0' \
    'rasterio>=1.3.9'

# Web and API libraries
RUN pip install --no-cache-dir \
    'fastapi>=0.108.0' \
    'uvicorn[standard]>=0.25.0' \
    'httpx>=0.26.0' \
    'requests>=2.31.0' \
    'redis>=5.0.0'

# Statistical and ML libraries
RUN pip install --no-cache-dir \
    'statsmodels>=0.14.0' \
    'scikit-learn>=1.4.0' \
    'pandas>=2.1.0'  # Keep for compatibility where needed

# Copy requirements files and install remaining dependencies
COPY requirements.txt /tmp/requirements.txt
COPY requirements-dev.txt /tmp/requirements-dev.txt

RUN pip install --no-cache-dir -r /tmp/requirements.txt
RUN pip install --no-cache-dir -r /tmp/requirements-dev.txt

# Create necessary directories with proper permissions
RUN mkdir -p /opt/airflow/duckdb_data \
    && mkdir -p /opt/airflow/cache \
    && mkdir -p /opt/airflow/temp \
    && chown -R airflow:root /opt/airflow/duckdb_data \
    && chown -R airflow:root /opt/airflow/cache \
    && chown -R airflow:root /opt/airflow/temp

# Set environment variables for optimal performance
ENV PYTHONPATH=/opt/airflow/src
ENV POLARS_MAX_THREADS=4
ENV DUCKDB_MEMORY_LIMIT=2GB
ENV AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT=300

# Health check for the service
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD python -c "import polars as pl; import duckdb; print('Health check passed')"

USER airflow

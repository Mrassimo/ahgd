{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad129f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"AHGD ETL Pipeline - Colab Runner\n",
    "\n",
    "This notebook runs the ETL pipeline by pulling code from GitHub and executing it in Colab.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2eee0",
   "metadata": {},
   "source": [
    "==============================================================================\n",
    "Cell 1: Mount Google Drive\n",
    "==============================================================================\n",
    "@title Mount Google Drive\n",
    "@markdown Mount your Google Drive to access data and save outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22354fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5175fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_mount_point = '/content/drive'\n",
    "print(f\"Attempting to mount Google Drive at {drive_mount_point}...\")\n",
    "try:\n",
    "    drive.mount(drive_mount_point, force_remount=True)\n",
    "    print(\"Google Drive mounted successfully.\")\n",
    "    # Basic check\n",
    "    if not Path(drive_mount_point + '/MyDrive').exists():\n",
    "         print(\"Warning: /content/drive/MyDrive not immediately found.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR mounting Google Drive: {e}\")\n",
    "    raise SystemExit(\"Google Drive mount failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Cell 2: Define and Verify Project Base Path\n",
    "# ==============================================================================\n",
    "# @title Define Project Base Path\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set the path where your project's code AND data will live on Drive ---\n",
    "drive_base_path_str = '/content/drive/MyDrive/Colab_Notebooks/AHGD_Project' # <<<--- VERIFY THIS IS CORRECT\n",
    "# -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b7cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(drive_base_path_str)\n",
    "print(f\"Target Project Base Directory set to: {BASE_DIR}\")\n",
    "try:\n",
    "    BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    test_file_path = BASE_DIR / \".writable_test\"\n",
    "    test_file_path.write_text('test'); test_file_path.unlink()\n",
    "    print(f\"Path '{BASE_DIR}' exists and is writable.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Project path '{BASE_DIR}' is not accessible/writable: {e}\")\n",
    "    raise SystemExit(\"Project path verification failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3119e0cf",
   "metadata": {},
   "source": [
    "==============================================================================\n",
    "Cell 3: Clone/Pull Code Repo & Install Dependencies\n",
    "==============================================================================\n",
    "@title Setup Code and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d77b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Git Configuration ---\n",
    "GIT_REPO_URL = \"https://github.com/Mrassimo/ahgd.git\"  # Your GitHub repository URL\n",
    "PROJECT_DIR_NAME = \"ahgd\" # Changed from ahgd-etl-pipeline to match actual repo name\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'BASE_DIR' not in globals(): raise NameError(\"BASE_DIR not defined. Run Cell 2 first.\")\n",
    "PROJECT_PATH = BASE_DIR / PROJECT_DIR_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77eb0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clone or Pull Repository ---\n",
    "print(\"Accessing Git repository...\")\n",
    "if not PROJECT_PATH.exists():\n",
    "    print(f\"Cloning repository into {PROJECT_PATH}...\")\n",
    "    print(f\"Running: cd {BASE_DIR}\")\n",
    "    get_ipython().run_line_magic('cd', str(BASE_DIR))\n",
    "    print(f\"Running: git clone {GIT_REPO_URL} {PROJECT_DIR_NAME}\")\n",
    "    !git clone {GIT_REPO_URL} {PROJECT_DIR_NAME}\n",
    "    print(f\"Running: cd {PROJECT_PATH}\")\n",
    "    get_ipython().run_line_magic('cd', str(PROJECT_PATH))\n",
    "else:\n",
    "    print(f\"Pulling latest changes into {PROJECT_PATH}...\")\n",
    "    print(f\"Running: cd {PROJECT_PATH}\")\n",
    "    get_ipython().run_line_magic('cd', str(PROJECT_PATH))\n",
    "    print(\"Running: git pull origin main\")\n",
    "    !git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc01ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install Dependencies ---\n",
    "print(\"\\nInstalling dependencies...\")\n",
    "req_file = PROJECT_PATH / 'requirements.txt'\n",
    "if req_file.exists():\n",
    "     print(f\"Installing requirements from: {req_file}\")\n",
    "     !pip install --quiet -r {str(req_file)}\n",
    "     print(\"Installed base requirements.\")\n",
    "else: print(\"Warning: requirements.txt not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing system dependencies...\")\n",
    "!apt-get update --quiet && apt-get install --quiet -y libspatialindex-dev python3-rtree > /dev/null\n",
    "!pip install --quiet rtree\n",
    "print(\"Geospatial dependencies installed/checked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf725fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Add project path to sys.path ---\n",
    "print(\"\\nPython Path Setup:\")\n",
    "print(f\"Current sys.path: {sys.path}\")\n",
    "if str(PROJECT_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_PATH))\n",
    "    print(f\"Added {PROJECT_PATH} to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug information\n",
    "print(\"\\nDebug Information:\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"PROJECT_PATH: {PROJECT_PATH}\")\n",
    "print(f\"PROJECT_PATH exists: {PROJECT_PATH.exists()}\")\n",
    "print(f\"PROJECT_PATH is directory: {PROJECT_PATH.is_dir()}\")\n",
    "print(f\"etl_logic path: {PROJECT_PATH/'etl_logic'}\")\n",
    "print(f\"etl_logic exists: {(PROJECT_PATH/'etl_logic').exists()}\")\n",
    "print(f\"etl_logic is directory: {(PROJECT_PATH/'etl_logic').is_dir()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1602cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDirectory Contents:\")\n",
    "print(f\"Contents of {PROJECT_PATH}:\")\n",
    "!ls -la {str(PROJECT_PATH)}\n",
    "print(f\"\\nContents of {PROJECT_PATH}/etl_logic (if exists):\")\n",
    "!ls -la {str(PROJECT_PATH)}/etl_logic || echo \"etl_logic directory not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab761db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to find etl_logic\n",
    "print(\"\\nSearching for etl_logic:\")\n",
    "!find {str(BASE_DIR)} -name \"etl_logic\" -type d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSetup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Cell 4: Import Logic and Configure Execution\n",
    "# ==============================================================================\n",
    "# @title Import Modules and Setup\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'BASE_DIR' not in globals(): raise NameError(\"BASE_DIR not defined. Run Cell 2 first.\")\n",
    "if 'PROJECT_PATH' not in globals() or str(PROJECT_PATH) not in sys.path:\n",
    "     raise NameError(\"Project path not set up. Run Cell 3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf724be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your custom modules\n",
    "try:\n",
    "    import sys\n",
    "    print(f\"Python path before import: {sys.path}\")\n",
    "    print(f\"Attempting to import from {PROJECT_PATH}\")\n",
    "    os.chdir(str(PROJECT_PATH))  # Change to project directory\n",
    "    from etl_logic import utils, config, geography, census\n",
    "    print(\"Successfully imported ETL modules.\")\n",
    "except ImportError as e:\n",
    "     print(f\"ERROR: Could not import modules from {PROJECT_PATH}/etl_logic.\")\n",
    "     print(f\"Current directory: {os.getcwd()}\")\n",
    "     print(f\"Directory contents:\")\n",
    "     !ls -la\n",
    "     raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup Logging ---\n",
    "PATHS = config.get_paths(BASE_DIR) # Get absolute paths\n",
    "logger = utils.setup_logging(log_directory=PATHS['LOG_DIR'])\n",
    "if not logger: raise RuntimeError(\"Failed to initialise logger.\")\n",
    "logger.info(\"Logger initialised for Colab execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243945fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Get Configuration for Pipeline ---\n",
    "required_geo_zips = config.get_required_geo_zips()\n",
    "required_census_zips = config.get_required_census_zips()\n",
    "all_zips_to_download = {**required_geo_zips, **required_census_zips}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display paths for verification\n",
    "logger.info(f\"Output Dir: {PATHS['OUTPUT_DIR']}\")\n",
    "logger.info(f\"Temp Zip Dir: {PATHS['TEMP_ZIP_DIR']}\")\n",
    "logger.info(f\"Temp Extract Dir: {PATHS['TEMP_EXTRACT_DIR']}\")\n",
    "logger.info(f\"Log File: {PATHS['LOG_DIR'] / 'ahgd_colab_run.log'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff58ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Imports and configuration loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19df1cb",
   "metadata": {},
   "source": [
    "==============================================================================\n",
    "Cell 5: Execute the Pipeline\n",
    "==============================================================================\n",
    "@title Run ETL Pipeline\n",
    "@markdown Execute the complete ETL pipeline using the imported logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe56801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2119f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'logger' not in globals() or 'PATHS' not in globals():\n",
    "    raise NameError(\"Setup incomplete. Run Cell 4 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aaba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pipeline Options ---\n",
    "force_download = False  # @param {type:\"boolean\"}\n",
    "force_continue = False  # @param {type:\"boolean\"}\n",
    "cleanup_temp = False    # @param {type:\"boolean\"}\n",
    "# ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74389d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"================= Pipeline Start =================\")\n",
    "start_time = time.time()\n",
    "overall_status = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11541e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Download ---\n",
    "logger.info(\"=== Download Phase Started ===\")\n",
    "download_success = utils.download_data(\n",
    "    urls_dict=all_zips_to_download,\n",
    "    download_dir=PATHS['TEMP_ZIP_DIR'],\n",
    "    force_download=force_download\n",
    ")\n",
    "if not download_success:\n",
    "    logger.error(\"=== Download Phase Failed ===\")\n",
    "    overall_status = False\n",
    "    if not force_continue: logger.critical(\"Exiting: Download failed & force_continue=False.\")\n",
    "else: logger.info(\"=== Download Phase Finished Successfully ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f4d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: ETL Processing ---\n",
    "if overall_status or force_continue:\n",
    "    if not overall_status: logger.warning(\"Proceeding with ETL despite Download failure.\")\n",
    "    logger.info(\"=== ETL Phase Started ===\")\n",
    "    etl_success_current = True\n",
    "\n",
    "    # Process Geography\n",
    "    if overall_status or force_continue:\n",
    "        logger.info(\"--- Starting Geography ETL Step ---\")\n",
    "        geo_success = geography.process_geography(\n",
    "            zip_dir=PATHS['TEMP_ZIP_DIR'],\n",
    "            temp_extract_base=PATHS['TEMP_EXTRACT_DIR'],\n",
    "            output_dir=PATHS['OUTPUT_DIR']\n",
    "        )\n",
    "        if not geo_success:\n",
    "            logger.error(\"--- Geography ETL Step Failed ---\")\n",
    "            etl_success_current = False\n",
    "            if not force_continue: overall_status = False\n",
    "        else: logger.info(\"--- Geography ETL Step Finished Successfully ---\")\n",
    "\n",
    "    # Process Population\n",
    "    geo_output_path = PATHS['OUTPUT_DIR'] / \"geo_dimension.parquet\"\n",
    "    if (geo_success or force_continue) and overall_status:\n",
    "         if not geo_success: logger.warning(\"Forcing Population ETL despite Geo failure.\")\n",
    "         logger.info(\"--- Starting Population (G01) ETL Step ---\")\n",
    "         pop_success = census.process_census_data(\n",
    "              zip_dir=PATHS['TEMP_ZIP_DIR'],\n",
    "              temp_extract_base=PATHS['TEMP_EXTRACT_DIR'],\n",
    "              output_dir=PATHS['OUTPUT_DIR'],\n",
    "              geo_output_path=geo_output_path\n",
    "         )\n",
    "         if not pop_success:\n",
    "              logger.error(\"--- Population (G01) ETL Step Failed ---\")\n",
    "              etl_success_current = False\n",
    "              if not force_continue: overall_status = False\n",
    "         else: logger.info(\"--- Population (G01) ETL Step Finished Successfully ---\")\n",
    "    elif not overall_status: logger.warning(\"Skipping Population ETL: Critical failure earlier.\")\n",
    "\n",
    "    if etl_success_current: logger.info(\"=== ETL Phase Finished Successfully ===\")\n",
    "    else: logger.error(\"=== ETL Phase Finished with Errors ===\")\n",
    "    overall_status = overall_status and etl_success_current\n",
    "else: logger.warning(\"Skipping ETL Phase due to Download failure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c1cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Cleanup ---\n",
    "if cleanup_temp:\n",
    "     logger.info(\"=== Cleanup Phase Started ===\")\n",
    "     try:\n",
    "         shutil.rmtree(PATHS['TEMP_ZIP_DIR'], ignore_errors=True)\n",
    "         shutil.rmtree(PATHS['TEMP_EXTRACT_DIR'], ignore_errors=True)\n",
    "         logger.info(\"Temporary directories cleaned up.\")\n",
    "     except Exception as e:\n",
    "         logger.error(f\"Cleanup failed: {e}\")\n",
    "else: logger.info(\"Skipping cleanup phase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4c424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Report ---\n",
    "end_time = time.time(); duration = end_time - start_time\n",
    "logger.info(f\"================= Pipeline End (Duration: {duration:.2f}s) =================\")\n",
    "log_file_path_final = PATHS['LOG_DIR'] / 'ahgd_colab_run.log'\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if overall_status:\n",
    "    logger.info(f\"Pipeline success ({duration:.2f}s).\")\n",
    "    print(f\"✅ Success ({duration:.2f}s).\")\n",
    "    print(f\"   Output: {PATHS['OUTPUT_DIR']}\")\n",
    "    print(f\"   Log: {log_file_path_final}\")\n",
    "else:\n",
    "    logger.error(f\"Pipeline failed ({duration:.2f}s).\")\n",
    "    print(f\"❌ Failed ({duration:.2f}s).\")\n",
    "    print(f\"   Check Log: {log_file_path_final}\")\n",
    "    print(\"   Review Colab output above.\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "print(\"Colab execution run complete.\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

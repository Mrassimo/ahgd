{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"AHGD ETL Pipeline - Colab Runner\n",
    "\n",
    "This notebook runs the ETL pipeline by pulling code from GitHub and executing it in Colab.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850779e8",
   "metadata": {},
   "source": [
    "==============================================================================\n",
    "Cell 1: Mount Google Drive\n",
    "==============================================================================\n",
    "@title Mount Google Drive\n",
    "@markdown Mount your Google Drive to access data and save outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_mount_point = '/content/drive'\n",
    "print(f\"Attempting to mount Google Drive at {drive_mount_point}...\")\n",
    "try:\n",
    "    drive.mount(drive_mount_point, force_remount=True)\n",
    "    print(\"Google Drive mounted successfully.\")\n",
    "    # Basic check\n",
    "    if not Path(drive_mount_point + '/MyDrive').exists():\n",
    "         print(\"Warning: /content/drive/MyDrive not immediately found.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR mounting Google Drive: {e}\")\n",
    "    raise SystemExit(\"Google Drive mount failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d26257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Cell 2: Define and Verify Project Base Path\n",
    "# ==============================================================================\n",
    "# @title Define Project Base Path\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set the path where your project's code AND data will live on Drive ---\n",
    "drive_base_path_str = '/content/drive/MyDrive/Colab_Notebooks/AHGD_Project' # <<<--- VERIFY THIS IS CORRECT\n",
    "# -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9971a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(drive_base_path_str)\n",
    "print(f\"Target Project Base Directory set to: {BASE_DIR}\")\n",
    "try:\n",
    "    BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    test_file_path = BASE_DIR / \".writable_test\"\n",
    "    test_file_path.write_text('test'); test_file_path.unlink()\n",
    "    print(f\"Path '{BASE_DIR}' exists and is writable.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Project path '{BASE_DIR}' is not accessible/writable: {e}\")\n",
    "    raise SystemExit(\"Project path verification failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4843c8b5",
   "metadata": {},
   "source": [
    "==============================================================================\n",
    "Cell 3: Clone/Pull Code Repo & Install Dependencies\n",
    "==============================================================================\n",
    "@title Setup Code and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473159dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf79b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Git Configuration ---\n",
    "GIT_REPO_URL = \"https://github.com/Mrassimo/ahgd.git\"  # Your GitHub repository URL\n",
    "PROJECT_DIR_NAME = \"ahgd\" # Changed from ahgd-etl-pipeline to match actual repo name\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc51ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'BASE_DIR' not in globals(): raise NameError(\"BASE_DIR not defined. Run Cell 2 first.\")\n",
    "PROJECT_PATH = BASE_DIR / PROJECT_DIR_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clone or Pull Repository ---\n",
    "print(\"Accessing Git repository...\")\n",
    "if not PROJECT_PATH.exists():\n",
    "    print(f\"Cloning repository into {PROJECT_PATH}...\")\n",
    "    \"%cd {BASE_DIR}\"\n",
    "    \"!git clone {GIT_REPO_URL} {PROJECT_DIR_NAME}\"\n",
    "    \"%cd {PROJECT_PATH}\"\n",
    "else:\n",
    "    print(f\"Pulling latest changes into {PROJECT_PATH}...\")\n",
    "    \"%cd {PROJECT_PATH}\"\n",
    "    \"!git pull origin main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625282dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install Dependencies ---\n",
    "print(\"\\nInstalling dependencies...\")\n",
    "req_file = PROJECT_PATH / 'requirements.txt'\n",
    "if req_file.exists():\n",
    "     \"!pip install --quiet -r {req_file}\"\n",
    "     print(\"Installed base requirements.\")\n",
    "else: print(\"Warning: requirements.txt not found.\")\n",
    "\"!apt-get update --quiet && apt-get install --quiet -y libspatialindex-dev python3-rtree > /dev/null\"\n",
    "\"!pip install --quiet rtree\"\n",
    "print(\"Geospatial dependencies installed/checked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3721f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Add project path to sys.path ---\n",
    "if str(PROJECT_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_PATH))\n",
    "    print(f\"Added {PROJECT_PATH} to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da798e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSetup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Cell 4: Import Logic and Configure Execution\n",
    "# ==============================================================================\n",
    "# @title Import Modules and Setup\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96423a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'BASE_DIR' not in globals(): raise NameError(\"BASE_DIR not defined. Run Cell 2 first.\")\n",
    "if 'PROJECT_PATH' not in globals() or str(PROJECT_PATH) not in sys.path:\n",
    "     raise NameError(\"Project path not set up. Run Cell 3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your custom modules\n",
    "try:\n",
    "    from etl_logic import utils, config, geography, census\n",
    "    print(\"Successfully imported ETL modules.\")\n",
    "except ImportError as e:\n",
    "     print(f\"ERROR: Could not import modules from {PROJECT_PATH}/etl_logic.\")\n",
    "     raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ab369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup Logging ---\n",
    "PATHS = config.get_paths(BASE_DIR) # Get absolute paths\n",
    "logger = utils.setup_logging(log_directory=PATHS['LOG_DIR'])\n",
    "if not logger: raise RuntimeError(\"Failed to initialise logger.\")\n",
    "logger.info(\"Logger initialised for Colab execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Get Configuration for Pipeline ---\n",
    "required_geo_zips = config.get_required_geo_zips()\n",
    "required_census_zips = config.get_required_census_zips()\n",
    "all_zips_to_download = {**required_geo_zips, **required_census_zips}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display paths for verification\n",
    "logger.info(f\"Output Dir: {PATHS['OUTPUT_DIR']}\")\n",
    "logger.info(f\"Temp Zip Dir: {PATHS['TEMP_ZIP_DIR']}\")\n",
    "logger.info(f\"Temp Extract Dir: {PATHS['TEMP_EXTRACT_DIR']}\")\n",
    "logger.info(f\"Log File: {PATHS['LOG_DIR'] / 'ahgd_colab_run.log'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc049d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Imports and configuration loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44fdd25",
   "metadata": {},
   "source": [
    "==============================================================================\n",
    "Cell 5: Execute the Pipeline\n",
    "==============================================================================\n",
    "@title Run ETL Pipeline\n",
    "@markdown Execute the complete ETL pipeline using the imported logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b810285",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'logger' not in globals() or 'PATHS' not in globals():\n",
    "    raise NameError(\"Setup incomplete. Run Cell 4 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bab47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pipeline Options ---\n",
    "force_download = False  # @param {type:\"boolean\"}\n",
    "force_continue = False  # @param {type:\"boolean\"}\n",
    "cleanup_temp = False    # @param {type:\"boolean\"}\n",
    "# ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492da471",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"================= Pipeline Start =================\")\n",
    "start_time = time.time()\n",
    "overall_status = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e328b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Download ---\n",
    "logger.info(\"=== Download Phase Started ===\")\n",
    "download_success = utils.download_data(\n",
    "    urls_dict=all_zips_to_download,\n",
    "    download_dir=PATHS['TEMP_ZIP_DIR'],\n",
    "    force_download=force_download\n",
    ")\n",
    "if not download_success:\n",
    "    logger.error(\"=== Download Phase Failed ===\")\n",
    "    overall_status = False\n",
    "    if not force_continue: logger.critical(\"Exiting: Download failed & force_continue=False.\")\n",
    "else: logger.info(\"=== Download Phase Finished Successfully ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: ETL Processing ---\n",
    "if overall_status or force_continue:\n",
    "    if not overall_status: logger.warning(\"Proceeding with ETL despite Download failure.\")\n",
    "    logger.info(\"=== ETL Phase Started ===\")\n",
    "    etl_success_current = True\n",
    "\n",
    "    # Process Geography\n",
    "    if overall_status or force_continue:\n",
    "        logger.info(\"--- Starting Geography ETL Step ---\")\n",
    "        geo_success = geography.process_geography(\n",
    "            zip_dir=PATHS['TEMP_ZIP_DIR'],\n",
    "            temp_extract_base=PATHS['TEMP_EXTRACT_DIR'],\n",
    "            output_dir=PATHS['OUTPUT_DIR']\n",
    "        )\n",
    "        if not geo_success:\n",
    "            logger.error(\"--- Geography ETL Step Failed ---\")\n",
    "            etl_success_current = False\n",
    "            if not force_continue: overall_status = False\n",
    "        else: logger.info(\"--- Geography ETL Step Finished Successfully ---\")\n",
    "\n",
    "    # Process Population\n",
    "    geo_output_path = PATHS['OUTPUT_DIR'] / \"geo_dimension.parquet\"\n",
    "    if (geo_success or force_continue) and overall_status:\n",
    "         if not geo_success: logger.warning(\"Forcing Population ETL despite Geo failure.\")\n",
    "         logger.info(\"--- Starting Population (G01) ETL Step ---\")\n",
    "         pop_success = census.process_census_data(\n",
    "              zip_dir=PATHS['TEMP_ZIP_DIR'],\n",
    "              temp_extract_base=PATHS['TEMP_EXTRACT_DIR'],\n",
    "              output_dir=PATHS['OUTPUT_DIR'],\n",
    "              geo_output_path=geo_output_path\n",
    "         )\n",
    "         if not pop_success:\n",
    "              logger.error(\"--- Population (G01) ETL Step Failed ---\")\n",
    "              etl_success_current = False\n",
    "              if not force_continue: overall_status = False\n",
    "         else: logger.info(\"--- Population (G01) ETL Step Finished Successfully ---\")\n",
    "    elif not overall_status: logger.warning(\"Skipping Population ETL: Critical failure earlier.\")\n",
    "\n",
    "    if etl_success_current: logger.info(\"=== ETL Phase Finished Successfully ===\")\n",
    "    else: logger.error(\"=== ETL Phase Finished with Errors ===\")\n",
    "    overall_status = overall_status and etl_success_current\n",
    "else: logger.warning(\"Skipping ETL Phase due to Download failure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Cleanup ---\n",
    "if cleanup_temp:\n",
    "     logger.info(\"=== Cleanup Phase Started ===\")\n",
    "     try:\n",
    "         shutil.rmtree(PATHS['TEMP_ZIP_DIR'], ignore_errors=True)\n",
    "         shutil.rmtree(PATHS['TEMP_EXTRACT_DIR'], ignore_errors=True)\n",
    "         logger.info(\"Temporary directories cleaned up.\")\n",
    "     except Exception as e:\n",
    "         logger.error(f\"Cleanup failed: {e}\")\n",
    "else: logger.info(\"Skipping cleanup phase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7cf7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Report ---\n",
    "end_time = time.time(); duration = end_time - start_time\n",
    "logger.info(f\"================= Pipeline End (Duration: {duration:.2f}s) =================\")\n",
    "log_file_path_final = PATHS['LOG_DIR'] / 'ahgd_colab_run.log'\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if overall_status:\n",
    "    logger.info(f\"Pipeline success ({duration:.2f}s).\")\n",
    "    print(f\"✅ Success ({duration:.2f}s).\")\n",
    "    print(f\"   Output: {PATHS['OUTPUT_DIR']}\")\n",
    "    print(f\"   Log: {log_file_path_final}\")\n",
    "else:\n",
    "    logger.error(f\"Pipeline failed ({duration:.2f}s).\")\n",
    "    print(f\"❌ Failed ({duration:.2f}s).\")\n",
    "    print(f\"   Check Log: {log_file_path_final}\")\n",
    "    print(\"   Review Colab output above.\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "print(\"Colab execution run complete.\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

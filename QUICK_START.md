# Australian Health Analytics - Quick Start Guide

## ðŸš€ Quick Setup (5 Minutes)

### Prerequisites
- Python 3.9+ 
- Git
- 4GB+ RAM recommended

### 1. Clone and Setup
```bash
git clone https://github.com/yourusername/australian-health-analytics.git
cd australian-health-analytics

# Install dependencies (UV recommended for speed)
pip install uv
uv sync

# Or use traditional pip
pip install -r requirements.txt
```

### 2. Initialize Project
```bash
# Quick setup with sample data
python scripts/setup/quick_start.py

# Or download real Australian government data (requires internet)
python scripts/setup/download_abs_data.py --states nsw,vic
```

### 3. Run Data Pipeline
```bash
# Process data through Bronze-Silver-Gold pipeline
python scripts/run_unified_etl.py

# Check processing status
python -c "from src.data_processing.core import AustralianHealthData; print('âœ… Pipeline ready')"
```

### 4. Launch Dashboard
```bash
# Interactive Streamlit dashboard
python scripts/launch_portfolio.py

# Or manual launch
streamlit run src/web/streamlit/dashboard.py --server.port 8501
```

### 5. Explore Results
- **Dashboard**: http://localhost:8501
- **GitHub Pages**: View `docs/index.html` for portfolio showcase
- **Data Outputs**: Check `data/outputs/` for processed results

## ðŸ“Š What You'll See

### Dashboard Features
- **Interactive SA2 Maps**: 2,454 Australian statistical areas
- **Health Risk Assessment**: SEIFA-based risk scoring
- **Performance Metrics**: 57.5% memory optimization achieved
- **Mobile Responsive**: Works on all devices

### Data Processing Results
- **497,181+ Records**: Real Australian health data processed
- **92.9% Integration**: Cross-dataset alignment success
- **<2 Second Load**: Optimized dashboard performance
- **Bronze-Silver-Gold**: Enterprise data lake architecture

## ðŸ§ª Run Tests

```bash
# Quick test suite
python -m pytest tests/test_data_processing/ -v

# Full comprehensive testing (Phase 5 complete)
python scripts/run_integration_tests.py

# Performance benchmarking
python scripts/run_data_quality_tests.py
```

## ðŸ³ Docker Alternative

```bash
# Build and run with Docker
docker build -t health-analytics .
docker run -p 8501:8501 health-analytics

# Access dashboard at http://localhost:8501
```

## ðŸ“ Key Directories

- `src/`: Core application code
- `data/`: Data lake (Bronze-Silver-Gold layers)
- `tests/`: Comprehensive testing framework (Phase 5)
- `docs/`: Documentation and GitHub Pages site
- `scripts/`: Utility scripts and automation

## ðŸŽ¯ Next Steps

1. **Explore Code**: Check `src/data_processing/` for data pipeline
2. **View Documentation**: Read `docs/reports/` for phase completion details
3. **Run Performance Tests**: Execute `tests/performance/` for benchmarking
4. **Customize Dashboard**: Modify `src/web/streamlit/dashboard.py`

## ðŸ”§ Troubleshooting

### Common Issues

**Import Errors:**
```bash
# Ensure Python path is set
export PYTHONPATH=$PWD/src:$PYTHONPATH
python -c "import src.data_processing.core; print('âœ… Imports working')"
```

**Data Download Issues:**
```bash
# Use sample data if network fails
python scripts/setup/create_mock_data.py
```

**Memory Issues:**
```bash
# Enable memory optimization
python -c "from src.data_processing.storage import MemoryOptimizer; optimizer = MemoryOptimizer(); print('Memory optimization enabled')"
```

### Performance Tips
- Use UV package manager for 5x faster installs
- Enable Polars lazy evaluation for large datasets
- Run dashboard with `--server.maxUploadSize 1000` for large file uploads

## ðŸ“š Documentation

- **Project Structure**: `PROJECT_STRUCTURE.md`
- **Phase Reports**: `docs/reports/`
- **API Documentation**: `docs/api/`
- **Testing Guide**: `tests/TEST_FRAMEWORK_DOCUMENTATION.md`

## ðŸŽ‰ Success Indicators

âœ… Dashboard loads in <2 seconds  
âœ… 497,181+ records processed successfully  
âœ… 92.9% data integration success rate  
âœ… 57.5% memory optimization achieved  
âœ… All Phase 5 tests passing  

**You're ready to explore enterprise-grade Australian health analytics!**
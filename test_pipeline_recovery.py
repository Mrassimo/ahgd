#!/usr/bin/env python3
"""Test script to validate the complete pipeline data recovery."""

import sys
from pathlib import Path

# Add src to path
sys.path.append('src')

from data_processing.census_processor import CensusProcessor
from data_processing.seifa_processor import SEIFAProcessor 
from data_processing.health_processor import HealthDataProcessor
from monitoring.data_volume_monitor import DataVolumeMonitor


def test_complete_pipeline():
    """Test the complete data processing pipeline."""
    print("ðŸš€ Starting Complete Pipeline Test")
    print("=" * 60)
    
    results = {}
    total_records = 0
    
    # Test 1: SEIFA Processing
    print("\n1ï¸âƒ£ Testing SEIFA Processing...")
    try:
        seifa_processor = SEIFAProcessor()
        seifa_df = seifa_processor.process_complete_pipeline()
        results['seifa'] = len(seifa_df)
        total_records += len(seifa_df)
        print(f"âœ… SEIFA: {len(seifa_df):,} records processed")
    except Exception as e:
        print(f"âŒ SEIFA failed: {e}")
        results['seifa'] = 0
    
    # Test 2: Census ZIP Extraction and Processing  
    print("\n2ï¸âƒ£ Testing Census ZIP Extraction...")
    try:
        census_processor = CensusProcessor()
        
        # First test just the extraction (already done above)
        extraction_dir = census_processor.extract_census_zips()
        csv_files = list(extraction_dir.rglob('*.csv'))
        print(f"âœ… Census ZIP extraction: {len(csv_files):,} CSV files extracted")
        
        # Test loading the extracted data (may be slow with 4GB)
        print("   Loading census data with lazy evaluation...")
        lazy_df = census_processor.load_census_datapack()
        print(f"âœ… Census data loaded successfully (lazy frame)")
        
        # Test basic demographics processing (sample first)
        print("   Processing basic demographics...")
        demographics_df = census_processor.process_basic_demographics()
        results['census'] = len(demographics_df)
        total_records += len(demographics_df)
        print(f"âœ… Census: {len(demographics_df):,} demographic records processed")
        
    except Exception as e:
        print(f"âŒ Census processing failed: {e}")
        results['census'] = 0
    
    # Test 3: Health Data Processing (without limits)
    print("\n3ï¸âƒ£ Testing Health Data Processing...")
    try:
        health_processor = HealthDataProcessor()
        health_summary = health_processor.process_complete_pipeline()
        
        if health_summary and isinstance(health_summary, dict):
            mbs_records = health_summary.get('mbs_records', 0)
            pbs_records = health_summary.get('pbs_records', 0)
            health_total = mbs_records + pbs_records
            results['health'] = health_total
            total_records += health_total
            print(f"âœ… Health: {mbs_records:,} MBS + {pbs_records:,} PBS = {health_total:,} total records")
        else:
            results['health'] = 0
            print("âš ï¸  Health processing returned no data")
            
    except Exception as e:
        print(f"âŒ Health processing failed: {e}")
        results['health'] = 0
    
    # Test 4: Data Volume Analysis
    print("\n4ï¸âƒ£ Running Data Volume Analysis...")
    try:
        monitor = DataVolumeMonitor()
        volume_results = monitor.monitor_pipeline_data_loss()
        monitor.print_summary_table(volume_results)
        
        overall_retention = volume_results['overall']['retention_rate']
        print(f"âœ… Overall retention rate: {overall_retention:.1f}%")
        
    except Exception as e:
        print(f"âŒ Volume analysis failed: {e}")
    
    # Final Summary
    print("\nðŸŽ‰ Pipeline Test Summary")
    print("=" * 60)
    print(f"ðŸ“Š Total Records Processed: {total_records:,}")
    print(f"ðŸ  SEIFA Records: {results.get('seifa', 0):,}")
    print(f"ðŸ“Š Census Records: {results.get('census', 0):,}")
    print(f"ðŸ¥ Health Records: {results.get('health', 0):,}")
    
    # Expected vs Actual
    expected_seifa = 2368  # Expected SA2 areas
    expected_census = 50000  # Conservative estimate for processed demographics
    expected_health = 100000  # Conservative estimate for health records
    
    print(f"\nðŸ“ˆ Recovery Analysis:")
    if results.get('seifa', 0) > expected_seifa * 0.9:
        print(f"âœ… SEIFA: Excellent recovery ({results.get('seifa', 0)} vs {expected_seifa} expected)")
    else:
        print(f"âš ï¸  SEIFA: Needs improvement ({results.get('seifa', 0)} vs {expected_seifa} expected)")
    
    if results.get('census', 0) > expected_census * 0.5:
        print(f"âœ… Census: Good recovery ({results.get('census', 0):,} vs {expected_census:,} expected)")
    else:
        print(f"âš ï¸  Census: Needs improvement ({results.get('census', 0):,} vs {expected_census:,} expected)")
    
    if results.get('health', 0) > expected_health * 0.5:
        print(f"âœ… Health: Good recovery ({results.get('health', 0):,} vs {expected_health:,} expected)")
    else:
        print(f"âš ï¸  Health: Needs improvement ({results.get('health', 0):,} vs {expected_health:,} expected)")
    
    return results


if __name__ == "__main__":
    results = test_complete_pipeline()
    
    # Success criteria
    total_processed = sum(results.values())
    if total_processed > 100000:  # At least 100k records
        print(f"\nðŸŽ‰ SUCCESS: Pipeline recovered {total_processed:,} records!")
        print("   This represents a massive improvement from the previous 95.1% data loss.")
        exit(0)
    else:
        print(f"\nâš ï¸  PARTIAL SUCCESS: {total_processed:,} records processed (expected >100k)")
        exit(1)